import streamlit as st
import os
import time
import google.generativeai as genai
import logging
from dotenv import load_dotenv
from utils import (
    
    check_data_files,
    load_data,
    run_parallel_agents,
    run_head_agent,
    get_conversation_history
)

# --- í™˜ê²½ ë³€ìˆ˜ ë° Gemini API ì„¤ì • ---
load_dotenv()
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê´€ì„¸ë²• íŒë¡€ ê¸°ë°˜ ì±—ë´‡",
    page_icon="âš–ï¸",
    layout="wide",
)

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª©
st.title("âš–ï¸ ê´€ì„¸ë²• íŒë¡€ ê¸°ë°˜ ì±—ë´‡")
st.markdown("ê´€ì„¸ë²• íŒë¡€ ì •ë³´ë¥¼ í™œìš©í•œ AI ê¸°ë°˜ ë²•ë¥  ì±—ë´‡ì…ë‹ˆë‹¤.")


# ëŒ€í™” ê´€ë ¨ ì„¤ì •
if "messages" not in st.session_state:
    st.session_state.messages = []

if "processing" not in st.session_state:
    st.session_state.processing = False

# ëŒ€í™” ë§¥ë½ ê´€ë¦¬ ì„¤ì •
if "context_enabled" not in st.session_state:
    st.session_state.context_enabled = True

# ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì„¤ì •
if "loaded_data" not in st.session_state:
    st.session_state.loaded_data = {
        "court_cases": [],
        "tax_cases": [],
        "preprocessed_data": {}
    }

with st.sidebar:
    st.header("ì„¤ì •")
    
    
    # ëŒ€í™” ê´€ë¦¬ ì˜µì…˜ë“¤
    st.header("ëŒ€í™” ê´€ë¦¬")
    
    # ëŒ€í™” ë§¥ë½ í™œìš© ì˜µì…˜
    context_enabled = st.checkbox("ì´ì „ ëŒ€í™” ë§¥ë½ í™œìš©", value=st.session_state.context_enabled)
    if context_enabled != st.session_state.context_enabled:
        st.session_state.context_enabled = context_enabled
        if context_enabled:
            st.success("ì´ì „ ëŒ€í™” ë§¥ë½ì„ í™œìš©í•©ë‹ˆë‹¤.")
        else:
            st.info("ê° ì§ˆë¬¸ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ìµœê·¼ ëŒ€í™” ìœ ì§€ ìˆ˜ ì„ íƒ
    if st.session_state.context_enabled:
        max_history = st.slider("ìµœê·¼ ëŒ€í™” ìœ ì§€ ìˆ˜", min_value=2, max_value=10, value=5)
        st.session_state.max_history = max_history
    
    # ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘ ë²„íŠ¼
    if st.button("ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘í•˜ê¸°"):
        # ë©”ì‹œì§€ ê¸°ë¡ë§Œ ì´ˆê¸°í™” (ë°ì´í„°ëŠ” ìœ ì§€)
        st.session_state.messages = []
        st.session_state.processing = False
        st.success("ìƒˆë¡œìš´ ëŒ€í™”ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì‹¤í–‰ ì‹œ ë°ì´í„° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
has_data_files = check_data_files()
if not has_data_files:
    st.warning("ì¼ë¶€ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ í•„ìš”í•œ íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
else:
    # ë°ì´í„°ê°€ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë“œ
    if not st.session_state.loaded_data["court_cases"]:
        with st.spinner("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            court_cases, tax_cases, preprocessed_data = load_data()
            st.session_state.loaded_data = {
                "court_cases": court_cases,
                "tax_cases": tax_cases,
                "preprocessed_data": preprocessed_data
            }
            st.success("ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì €ì¥ëœ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ì²˜ë¦¬ ì‹œì‘
    st.session_state.processing = True
    
    # ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                # ì €ì¥ëœ ë°ì´í„° ì‚¬ìš©
                court_cases = st.session_state.loaded_data["court_cases"]
                tax_cases = st.session_state.loaded_data["tax_cases"]
                preprocessed_data = st.session_state.loaded_data["preprocessed_data"]
                
                # ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°
                conversation_history = ""
                if st.session_state.context_enabled:
                    conversation_history = get_conversation_history(
                        max_messages=st.session_state.get('max_history', 5)
                    )
                
                # í”„ë¡œê·¸ë ˆìŠ¤ ë°” í‘œì‹œ
                progress_text = st.empty()
                progress_bar = st.progress(0)
                
                # ë‹¨ê³„ë³„ ì§„í–‰ ìƒíƒœ í‘œì‹œ
                progress_text.text("1/3 ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
                progress_bar.progress(33)
                
                # ì—ì´ì „íŠ¸ ì‹¤í–‰ (ëŒ€í™” ê¸°ë¡ ì „ë‹¬ ë° ì „ì²˜ë¦¬ëœ ë°ì´í„° í™œìš©)
                agent_responses = run_parallel_agents(
                    court_cases, tax_cases, preprocessed_data, prompt, conversation_history
                )
                
                progress_text.text("2/3 ê²°ê³¼ í†µí•© ì¤‘...")
                progress_bar.progress(66)
                
                # Head Agentë¡œ ìµœì¢… ì‘ë‹µ ìƒì„± (ëŒ€í™” ê¸°ë¡ ì „ë‹¬)
                
                head_response = run_head_agent(
                    agent_responses, prompt, conversation_history
                )
                
                # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìˆ˜ì •ëœ í•¨ìˆ˜ ë°˜í™˜ê°’ì— ë§ì¶¤)
                if isinstance(head_response, dict):
                    final_response = head_response.get("response", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    already_displayed = head_response.get("already_displayed", False)
                else:
                    # ì´ì „ ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ì²˜ë¦¬
                    final_response = head_response
                    already_displayed = False
                
                progress_text.text("3/3 ë‹µë³€ ìƒì„± ì™„ë£Œ")
                progress_bar.progress(100)
                time.sleep(0.5)  # ì™„ë£Œ ìƒíƒœ ì ì‹œ í‘œì‹œ
                
                # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì œê±°
                progress_text.empty()
                progress_bar.empty()
                
                # ì´ë¯¸ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í‘œì‹œë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ìµœì¢… ì‘ë‹µ í‘œì‹œ
                if not already_displayed:
                    st.markdown(final_response)

                # ê° ì—ì´ì „íŠ¸ì˜ ì‘ë‹µì„ expanderë¡œ í‘œì‹œ
                with st.expander("ğŸ¤– ê° ì—ì´ì „íŠ¸ ë‹µë³€ ë³´ê¸°"):
                    for i, agent_resp in enumerate(agent_responses):
                        st.subheader(f"ğŸ“‹ {agent_resp['agent']}")
                        st.markdown(agent_resp['response'])
                        if i < len(agent_responses) - 1:  # ë§ˆì§€ë§‰ ì—ì´ì „íŠ¸ê°€ ì•„ë‹ˆë©´ êµ¬ë¶„ì„  ì¶”ê°€
                            st.divider()
                
                # ì‘ë‹µ ì €ì¥
                st.session_state.messages.append({"role": "assistant", "content": final_response})
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                logging.error(f"ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                # ì˜¤ë¥˜ ë©”ì‹œì§€ë„ ì €ì¥
                error_message = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.session_state.messages.append({"role": "assistant", "content": error_message})
    
    # ì²˜ë¦¬ ì™„ë£Œ
    st.session_state.processing = False

# ì‚¬ì´ë“œë°”ì— ì‚¬ìš© ì˜ˆì‹œ ë° ì •ë³´ ì¶”ê°€
with st.sidebar:
    st.subheader("í”„ë¡œì íŠ¸ ì •ë³´")
    st.markdown("""
    ì´ ì±—ë´‡ì€ ê´€ì„¸ë¶„ì•¼ì•¼ íŒë¡€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - 7ê°œì˜ AI ì—ì´ì „íŠ¸ í™œìš©
    - ì¼ë°˜ agent : Google Gemini 2.0 Flash ëª¨ë¸ ì‚¬ìš©
    - Head agent : Google Gemini 2.5 Flash ëª¨ë¸ ì‚¬ìš©
    - ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ íŒë¡€ ê²€ìƒ‰ ê¸°ëŠ¥
    - ê´€ë ¨ ìë£Œ ê¸°ë°˜ ì •í™•í•œ ì‘ë‹µ ìƒì„±
    """)